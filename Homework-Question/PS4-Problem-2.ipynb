{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS5220 Problem Set 4\n",
    "\n",
    "# Problem 2\n",
    "\n",
    "# Implement a two-layer neural network to recognize hand-written digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below line and run to install required packages if you have not done so\n",
    "\n",
    "# !pip install torch torchvision matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import trange\n",
    "\n",
    "%matplotlib inline\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 1234\n",
    "# cuDNN uses nondeterministic algorithms, set some options for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get MNIST Data\n",
    "The `torchvision` package provides a wrapper to download MNIST data. The cell below downloads the training and test datasets and creates dataloaders for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial transform (convert to PyTorch Tensor only)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "\n",
    "## Use the following lines to check the basic statistics of this dataset\n",
    "# Calculate training data mean and standard deviation to apply normalization to data\n",
    "# train_data.data are of type uint8 (range 0,255) so divide by 255.\n",
    "# train_mean = train_data.data.double().mean() / 255.\n",
    "# train_std = train_data.data.double().std() / 255.\n",
    "# print(f'Train Data: Mean={train_mean}, Std={train_std}')\n",
    "\n",
    "## Optional: Perform normalization of train and test data using calculated training mean and standard deviation\n",
    "# This will convert data to be approximately standard normal\n",
    "#transform = transforms.Compose([\n",
    "#    transforms.ToTensor(),\n",
    "#    transforms.Normalize((train_mean, ), (train_std, ))\n",
    "#])\n",
    "\n",
    "train_data.transform = transform\n",
    "test_data.transform = transform\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(seed)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=True) \n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Inspect dataset (0 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Randomly sample 20 images of the training dataset\n",
    "# To visualize the i-th sample, use the following code\n",
    "# > plt.subplot(4, 5, i+1)\n",
    "# > plt.imshow(images[i].squeeze(), cmap='gray', interpolation='none')\n",
    "# > plt.title(f'Label: {labels[i]}', fontsize=14)\n",
    "# > plt.axis('off')\n",
    "\n",
    "images, labels = iter(train_loader).next()\n",
    "\n",
    "# Print information and statistics of the first batch of images\n",
    "print(\"Images shape: \", images.shape)\n",
    "print(\"Labels shape: \", labels.shape)\n",
    "print(f'Mean={images.mean()}, Std={images.std()}')\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "# ------------------\n",
    "# Write your implementation here\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Implement a two-layer neural network\n",
    "\n",
    "Write a class that constructs a two-layer neural network as specified in the handout. The class consists of two methods, an initialization that sets up the architecture of the model, and a forward pass function given an input feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_size = 1 * 28 * 28  # input spatial dimension of images\n",
    "hidden_size = 128         # width of hidden layer\n",
    "output_size = 10          # number of output neurons\n",
    "\n",
    "class MNISTClassifierMLP(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.flatten = torch.nn.Flatten(start_dim=1)\n",
    "        # ------------------\n",
    "        # Write your implementation here.\n",
    "\n",
    "        self.fc1 = None\n",
    "        self.act = None\n",
    "        self.fc2 = None\n",
    "        self.log_softmax = None\n",
    "\n",
    "        # ------------------\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input image is of shape [batch_size, 1, 28, 28]\n",
    "        # Need to flatten to [batch_size, 784] before feeding to fc1\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # ------------------\n",
    "        # Write your implementation here.        \n",
    "\n",
    "        y_output = x\n",
    "        \n",
    "        return y_output\n",
    "        # ------------------\n",
    "\n",
    "model = MNISTClassifierMLP().to(DEVICE)\n",
    "\n",
    "# sanity check\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implement an optimizer to train the neural net model\n",
    "\n",
    "Write a method called `train_one_epoch` that runs one step using the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_loader, model, device, optimizer, log_interval, epoch):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    counter = []\n",
    "    \n",
    "    for i, (img, label) in enumerate(train_loader):\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "        # ------------------\n",
    "        # Write your implementation here.\n",
    "        \n",
    "               \n",
    "        # ------------------\n",
    "    \n",
    "        # Record training loss every log_interval and keep counter of total training images seen\n",
    "        if (i+1) % log_interval == 0:\n",
    "            losses.append(loss.item())\n",
    "            counter.append(\n",
    "                (i * batch_size) + img.size(0) + epoch * len(train_loader.dataset))\n",
    "\n",
    "    return losses, counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Run the optimization procedure and test the trained model\n",
    "\n",
    "Write a method called `test_one_epoch` that evalutes the trained model on the test dataset. Return the average test loss and the number of samples that the model predicts correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(test_loader, model, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    num_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(test_loader):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "\n",
    "            # ------------------\n",
    "            # Write your implementation here.\n",
    "            \n",
    "            output = None\n",
    "            pred = None # Get index of largest log-probability and use that as prediction\n",
    "            num_correct += None\n",
    "            test_loss += None\n",
    "\n",
    "            # ------------------\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    return test_loss, num_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using the cell below. Hyperparameters are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 0.01\n",
    "max_epochs=10\n",
    "gamma = 0.95\n",
    "\n",
    "# Recording data\n",
    "log_interval = 100\n",
    "\n",
    "# Instantiate optimizer (model was created in previous cell)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_correct = []\n",
    "for epoch in trange(max_epochs, leave=True, desc='Epochs'):\n",
    "    train_loss, counter = train_one_epoch(train_loader, model, DEVICE, optimizer, log_interval, epoch)\n",
    "    test_loss, num_correct = test_one_epoch(test_loader, model, DEVICE)\n",
    "\n",
    "    # Record results\n",
    "    train_losses.extend(train_loss)\n",
    "    train_counter.extend(counter)\n",
    "    test_losses.append(test_loss)\n",
    "    test_correct.append(num_correct)\n",
    "\n",
    "print(f\"Test accuracy: {test_correct[-1]/len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Inspection\n",
    "\n",
    "1. Plot the loss curve as the number of epochs increases.\n",
    "\n",
    "2. Show the predictions of the first 20 images of the test set.\n",
    "\n",
    "3. Show the first 20 images that the model predicted incorrectly. Discuss about some of the common scenarios that the model predicted incorrectly.\n",
    "\n",
    "4. Go back to Part 0, where we created the tranform component to apply on the training and test datasets. Re-run the code by uncommenting the normalization step, so that the training and test dataset have mean zero and unit variance. Report the result after this normalization step again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Draw training loss curve\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.plot(train_counter, train_losses, label='Train loss')\n",
    "plt.plot([i * len(train_loader.dataset) for i in range(1, max_epochs + 1)], \n",
    "         test_losses, label='Test loss', marker='o')\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(bottom=0)\n",
    "plt.title('Loss curve', fontsize=24)\n",
    "plt.xlabel('Number of training examples seen', fontsize=16)\n",
    "plt.ylabel('NLL', fontsize=16)\n",
    "plt.legend(loc='upper right', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Show the predictions of the first 20 images of the test dataset\n",
    "images, labels = iter(test_loader).next()\n",
    "images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "output = model(images)\n",
    "pred = output.argmax(dim=1)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 11))\n",
    "\n",
    "# ------------------\n",
    "# Write your implementation here. Use the code provided in Part 0 to visualize the images.\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Get 20 incorrect predictions in test dataset\n",
    "\n",
    "# Collect the images, predictions, labels for the first 20 incorrect predictions\n",
    "# Initialize empty tensors and then keep appending to the tensor.\n",
    "# Make sure that the first dimension of the tensors is the total number of incorrect\n",
    "# predictions seen so far\n",
    "# Ex) incorrect_imgs should be of shape i x C x H x W, where i is the total number of \n",
    "# incorrect images so far.\n",
    "incorrect_imgs = torch.Tensor().to(DEVICE)\n",
    "incorrect_preds = torch.IntTensor().to(DEVICE)\n",
    "incorrect_labels = torch.IntTensor().to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test set iterator\n",
    "    it = iter(test_loader)\n",
    "    # Loop over the test set batches until incorrect_imgs.size(0) >= 20\n",
    "    while incorrect_imgs.size(0) < 20:\n",
    "        images, labels = it.next()\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        # ------------------\n",
    "        # Write your implementation here.\n",
    "\n",
    "        output = None\n",
    "        pred = None\n",
    "\n",
    "        # Compare prediction and true labels and append the incorrect predictions\n",
    "        # using `torch.cat`. \n",
    "        incorrect_imgs = None\n",
    "        incorrect_preds = None\n",
    "        incorrect_labels = None\n",
    "                \n",
    "        # ------------------\n",
    "                \n",
    "# Show the first 20 wrong predictions in test set\n",
    "fig = plt.figure(figsize=(12, 11))\n",
    "for i in range(20):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    plt.imshow(incorrect_imgs[i].squeeze().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "    plt.title(f'Prediction: {incorrect_preds[i].item()}\\nLabel: {incorrect_labels[i].item()}', fontsize=14)\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
