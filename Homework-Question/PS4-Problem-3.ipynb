{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS5220 Problem Set 4\n",
    "\n",
    "# Problem 3\n",
    "\n",
    "# Implement a convolutional neural network to recognize hand-written digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below line and run to install required packages if you have not done so\n",
    "\n",
    "!pip install torch torchvision matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import trange\n",
    "\n",
    "%matplotlib inline\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 1234\n",
    "# cuDNN uses nondeterministic algorithms, set some options for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get MNIST Data\n",
    "The `torchvision` package provides a wrapper to download MNIST data. The cell below downloads the training and test datasets and creates dataloaders for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial transform (convert to PyTorch Tensor only)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "\n",
    "## Use the following lines to check the basic statistics of this dataset\n",
    "# Calculate training data mean and standard deviation to apply normalization to data\n",
    "# train_data.data are of type uint8 (range 0,255) so divide by 255.\n",
    "# train_mean = train_data.data.double().mean() / 255.\n",
    "# train_std = train_data.data.double().std() / 255.\n",
    "# print(f'Train Data: Mean={train_mean}, Std={train_std}')\n",
    "\n",
    "## Optional: Perform normalization of train and test data using calculated training mean and standard deviation\n",
    "# This will convert data to be approximately standard normal\n",
    "#transform = transforms.Compose([\n",
    "#    transforms.ToTensor(),\n",
    "#    transforms.Normalize((train_mean, ), (train_std, ))\n",
    "#])\n",
    "\n",
    "train_data.transform = transform\n",
    "test_data.transform = transform\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(seed)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=True) \n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Inspect dataset (0 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Randomly sample 20 images of the training dataset\n",
    "# To visualize the i-th sample, use the following code\n",
    "# > plt.subplot(4, 5, i+1)\n",
    "# > plt.imshow(images[i].squeeze(), cmap='gray', interpolation='none')\n",
    "# > plt.title(f'Label: {labels[i]}', fontsize=14)\n",
    "# > plt.axis('off')\n",
    "\n",
    "images, labels = iter(train_loader).next()\n",
    "\n",
    "# Print information and statistics of the first batch of images\n",
    "print(\"Images shape: \", images.shape)\n",
    "print(\"Labels shape: \", labels.shape)\n",
    "print(f'Mean={images.mean()}, Std={images.std()}')\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "# ------------------\n",
    "# Copy the implementation from Problem 4 here\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a convolutional neural network (10 points)\n",
    "\n",
    "Write a class that constructs a two-layer neural network as specified in the handout. The class consists of two methods, an initialization that sets up the architecture of the model, and a forward pass function given an input feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_size = 1 * 28 * 28  # input spatial dimension of images\n",
    "hidden_size = 128         # width of hidden layer\n",
    "output_size = 10          # number of output neurons\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.flatten = torch.nn.Flatten(start_dim=1)\n",
    "        # ------------------\n",
    "        # Write your implementation here.\n",
    "        self.conv1 = None # first convolutional layer\n",
    "        self.conv2 = None # second convolutional layer\n",
    "        self.fc = None # third fully-connected layer\n",
    "        # ------------------\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input image is of shape [batch_size, 1, 28, 28]\n",
    "        # Need to flatten to [batch_size, 784] before feeding to fc1\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # ------------------\n",
    "        # Write your implementation here.        \n",
    "\n",
    "        y_output = x\n",
    "        \n",
    "        return y_output\n",
    "        # ------------------\n",
    "\n",
    "model = CNN().to(DEVICE)\n",
    "\n",
    "# sanity check\n",
    "print(model)\n",
    "from torchsummary import summary\n",
    "summary(model, (1,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a method called `train_one_epoch` that runs one step using the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_loader, model, device, optimizer, log_interval, epoch):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    counter = []\n",
    "    \n",
    "    for i, (img, label) in enumerate(train_loader):\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "        # ------------------\n",
    "        # Copy the implementation from Problem 4 here\n",
    "        \n",
    "               \n",
    "        # ------------------\n",
    "    \n",
    "        # Record training loss every log_interval and keep counter of total training images seen\n",
    "        if (i+1) % log_interval == 0:\n",
    "            losses.append(loss.item())\n",
    "            counter.append(\n",
    "                (i * batch_size) + img.size(0) + epoch * len(train_loader.dataset))\n",
    "\n",
    "    return losses, counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a method called `test_one_epoch` that evalutes the trained model on the test dataset. Return the average test loss and the number of samples that the model predicts correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(test_loader, model, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    num_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(test_loader):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "\n",
    "            # ------------------\n",
    "            # Copy the implementation from Problem 2 here\n",
    "            \n",
    "            output = None\n",
    "            pred = None # Get index of largest log-probability and use that as prediction\n",
    "            num_correct += None\n",
    "            test_loss += None\n",
    "\n",
    "            # ------------------\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    return test_loss, num_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using the cell below. Hyperparameters are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 0.01\n",
    "max_epochs=10\n",
    "gamma = 0.95\n",
    "\n",
    "# Recording data\n",
    "log_interval = 100\n",
    "\n",
    "# Instantiate optimizer (model was created in previous cell)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_correct = []\n",
    "for epoch in trange(max_epochs, leave=True, desc='Epochs'):\n",
    "    train_loss, counter = train_one_epoch(train_loader, model, DEVICE, optimizer, log_interval, epoch)\n",
    "    test_loss, num_correct = test_one_epoch(test_loader, model, DEVICE)\n",
    "\n",
    "    # Record results\n",
    "    train_losses.extend(train_loss)\n",
    "    train_counter.extend(counter)\n",
    "    test_losses.append(test_loss)\n",
    "    test_correct.append(num_correct)\n",
    "\n",
    "print(f\"Test accuracy: {test_correct[-1]/len(test_loader.dataset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
